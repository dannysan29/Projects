{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Data Processing with Python\n",
    "\n",
    "In the digital era, data is omnipresent and growing exponentially in volume, variety, and velocity. Whether it's the performance statistics of a sports team or customer transactions in a business, data's value can only be unlocked through effective processing and management. Python, renowned for its simplicity and power, is one of the leading languages for data-related tasks. Its comprehensive standard library and third-party modules make it an ideal candidate for data processing, from simple CSV files to complex databases.\n",
    "\n",
    "When dealing with historical data, such as the comprehensive records of the Chicago Bears, one often encounters data in various formats, with CSV being one of the most common due to its simplicity and widespread support by data tools. CSV stands for Comma-Separated Values, a plain text format that represents tabular data. It's human-readable and can be easily edited with text editors or spreadsheet software. However, CSV files have limitations, particularly regarding data manipulation and querying capabilities.\n",
    "\n",
    "Enter databases — structured systems that provide efficient ways to store, retrieve, and manipulate data. SQLite, in particular, is a database engine that requires no configuration or server setup, making it an excellent choice for developing applications and for educational purposes. It offers the power of SQL with the simplicity of a file-based storage mechanism.\n",
    "\n",
    "For learners with a foundational grasp of Python, understanding how to process CSV files and how to interact with SQLite databases is a significant leap towards mastering data management. It opens doors to various applications, from data analytics to backend development for web applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Syntax and Modules\n",
    "\n",
    "To embark on this journey, let's first get acquainted with the essential tools at our disposal:\n",
    "\n",
    "CSV Module: Python's built-in csv module is our gateway to reading from and writing to CSV files. It provides the csv.reader for parsing CSV files into lists, and the csv.DictReader for parsing them into dictionaries, which is often more convenient as it allows us to access columns by header names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Example of reading CSV data into a list of dictionaries\n",
    "with open('file.csv', mode='r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        print(row)  # Each row is a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite3 Module: The sqlite3 module is Python's way of interacting with SQLite databases. It provides functionalities to create connections, execute SQL statements, and manage transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Example of creating a new SQLite database and table\n",
    "conn = sqlite3.connect('example.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('CREATE TABLE IF NOT EXISTS table_name (column1, column2, ...)')\n",
    "cursor.execute('INSERT INTO table_name (column1, column2, ...) VALUES (value1, value2, ...)')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Examples of the Pattern in Use\n",
    "\n",
    "Example 1: Extracting Specific Data from a CSV File\n",
    "\n",
    "Suppose we have a CSV file with many columns, but we're only interested in a few. Here's how we might extract just the relevant data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Assume our CSV has many columns, but we only want the 'Name' and 'Department'\n",
    "with open('company.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        print(f\"{row['Name']} works in {row['Department']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet reads each row from company.csv and prints out the employee's name and department."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: Adding Data to a Database\n",
    "\n",
    "Now, let's see how we can add data to our SQLite database using information from a Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Sample data\n",
    "employees = [('Alice', 'Engineering'), ('Bob', 'Sales')]\n",
    "\n",
    "# Connect to the database and insert data\n",
    "conn = sqlite3.connect('company.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.executemany('INSERT INTO employees (name, department) VALUES (?, ?)', employees)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, executemany is used to insert multiple rows into the employees table in one go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longer Problem Demo: Importing Chicago Bears Historical Data into SQLite\n",
    "\n",
    "We are presented with a dataset — chicago_bears.csv — which chronicles the historical performance of the Chicago Bears. This CSV file contains various columns, such as Year, Wins, Losses, and other game statistics. Our task is to import this rich dataset into an SQLite database for more efficient querying and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge involves several key steps:\n",
    "\n",
    "1. Parsing the CSV File: We need to read the data from the CSV file, ensuring we accurately capture the contents of each column.\n",
    "\n",
    "2. Database Table Creation: We must create a table in our SQLite database with a schema that mirrors the structure of our CSV data.\n",
    "\n",
    "3. Data Insertion: We need to insert each record from the CSV file into our database table.\n",
    "\n",
    "4. Exception Handling: Throughout this process, we should be mindful of potential errors, such as data type mismatches or SQL injection vulnerabilities, and handle them appropriately to maintain data integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution Steps:\n",
    "\n",
    "1. Database Connection and Table Creation:\n",
    "\n",
    "First, we establish a connection to an SQLite database and create a table that corresponds to the structure of our CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connecting to SQLite database\n",
    "conn = sqlite3.connect('bears_history.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Creating a table with columns matching the CSV file\n",
    "cur.execute('''\n",
    "CREATE TABLE IF NOT EXISTS bears_history (\n",
    "    Year INTEGER PRIMARY KEY,\n",
    "    Wins INTEGER,\n",
    "    Losses INTEGER,\n",
    "    Ties INTEGER,\n",
    "    PointsFor INTEGER,\n",
    "    PointsAgainst INTEGER,\n",
    "    Coach TEXT,\n",
    "    TopPasser TEXT,\n",
    "    TopRusher TEXT,\n",
    "    TopReceiver TEXT,\n",
    "    OffensiveRank INTEGER,\n",
    "    DefensiveRank INTEGER,\n",
    "    OverallRank INTEGER\n",
    "    -- Add other columns as needed\n",
    ")\n",
    "''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the CREATE TABLE IF NOT EXISTS statement to avoid creating a duplicate table if it already exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Reading and Inserting CSV Data:\n",
    "\n",
    "Next, we read our CSV file and insert each row into our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('chicago_bears.csv', 'r') as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "\n",
    "    for row in csvreader:\n",
    "        cur.execute('''\n",
    "        INSERT INTO bears_history (Year, Wins, Losses, Ties, PointsFor, PointsAgainst,\n",
    "        Coach, TopPasser, TopRusher, TopReceiver, OffensiveRank, DefensiveRank, OverallRank)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (row['Year'], row['Wins'], row['Losses'], row['Ties'], row['PointsFor'],\n",
    "              row['PointsAgainst'], row['Coach'], row['TopPasser'], row['TopRusher'],\n",
    "              row['TopReceiver'], row['OffensiveRank'], row['DefensiveRank'], row['OverallRank']))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we iterate over each row in our CSV file, using parameterized SQL queries to insert data. This method not only prevents SQL injection but also handles data type conversion automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Closing the Database Connection:\n",
    "\n",
    "Finally, it's crucial to close the database connection once our operations are complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properly closing the database connection is a good practice to prevent database locks and other potential issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Explanation:\n",
    "\n",
    "Through this exercise, we've demonstrated the entire process of taking a real-world dataset — the historical data of a prominent NFL team — and transitioning it from a flat-file format (CSV) into a structured database. This not only makes the data more accessible for complex queries but also introduces practices like creating resilient database schemas, writing secure SQL statements, and handling database connections responsibly.\n",
    "\n",
    "The skills learned here are applicable in a wide range of scenarios, from developing data-driven applications to performing data analysis for sports teams. By understanding these principles, students can better appreciate the importance of data in today's world and how Python can be an invaluable tool in managing it."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
